# Omnidirectional Depth Estimation

## Estimate 360$^\circ$ depth maps from **Fish-eye cameras**
1. Sweepnet: Wide-baseline omnidirectional depth estimation. ICRA 2019. [paper](https://arxiv.org/abs/1902.10904). [code](https://github.com/hyu-cvlab/sweepnet)
2. Omnimvs: End-to-end learning for omnidirectional stereo matching. ICCV 2019. [paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Won_OmniMVS_End-to-End_Learning_for_Omnidirectional_Stereo_Matching_ICCV_2019_paper.html). [code](https://github.com/hyu-cvlab/omnimvs-pytorch)
3. End-to-end learning for omnidirectional stereo matching with uncertainty prior. IEEE TPAMI 2020. [paper](https://ieeexplore.ieee.org/document/9086445). [code](https://github.com/hyu-cvlab/omnimvs-pytorch)

## Estimate 360$^\circ$ depth maps from **Panoramas**

### Monocular
1. EGformer: Equirectangular Geometry-biased Transformer for 360 Depth Estimation. ICCV 2023. [paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.pdf)
1. PanoFormer: Panorama Transformer for Indoor 360° Depth Estimation. ECCV 2022. [paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19769-7_12.pdf)
2. OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion. CVPR 2022. [paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.pdf). [code](https://github.com/yuyanli0831/OmniFusion).
3. 360MonoDepth: High-Resolution 360° Monocular Depth Estimation. CVPR 2022. [paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.pdf). [code](https://manurare.github.io/360monodepth/)
4. Unifuse: Unidirectional fusion for 360° panorama depth estimation. IEEE RAL 2021. [paper](https://arxiv.org/abs/2102.03550). [code](https://github.com/alibaba/UniFuse-Unidirectional-Fusion)
5. Spherical view synthesis for self-supervised 360° depth estimation. 3DV 2019. [paper](https://arxiv.org/abs/1909.08112). [code](https://github.com/VCL3D/SphericalViewSynthesis)
6. Omnidepth: Dense depth estimation for indoors spherical panoramas. ECCV 2018. [paper](https://arxiv.org/pdf/1807.09620.pdf)
7. Bifuse: Monocular 360 depth estimation via bi-projection fusion. CVPR 2020. [paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_BiFuse_Monocular_360_Depth_Estimation_via_Bi-Projection_Fusion_CVPR_2020_paper.html), [code](https://github.com/Yeh-yu-hsuan/BiFuse)

### Binocular
1. 360sd-net: 360◦ stereo depth estimation with learnable cost volume. ICRA 2020. [web](https://albert100121.github.io/360SD-Net-Project-Page/). [paper](https://arxiv.org/abs/1911.04460v2). [code](https://github.com/albert100121/360SD-Net)
2. Omnidirectional stereo depth estimation based on spherical deep network. IVC 2021. [paper](https://www.sciencedirect.com/science/article/abs/pii/S0262885621001694)
3. Uniform Subdivision of Omnidirectional Camera Space
for Efficient Spherical Stereo Matching. CVPR 2022. [paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.pdf).

### Multi-view
1. MODE: Multi-view Omnidirectional Depth Estimation with 360◦ Cameras. ECCV 2022. [paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19827-4_12.pdf). [code](https://github.com/nju-ee/MODE-2022).

